{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"Train.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_102659</td>\n",
       "      <td>04-JUL-04</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR_189752</td>\n",
       "      <td>18-JUL-17</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR_184637</td>\n",
       "      <td>15-MAR-17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CR_139071</td>\n",
       "      <td>13-FEB-09</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CR_109335</td>\n",
       "      <td>13-APR-05</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  INCIDENT_ID       DATE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  X_9  X_10  \\\n",
       "0   CR_102659  04-JUL-04    0   36   34    2    1    5    6    1    6     1   \n",
       "1   CR_189752  18-JUL-17    1   37   37    0    0   11   17    1    6     1   \n",
       "2   CR_184637  15-MAR-17    0    3    2    3    5    1    0    2    3     1   \n",
       "3   CR_139071  13-FEB-09    0   33   32    2    1    7    1    1    6     1   \n",
       "4   CR_109335  13-APR-05    0   33   32    2    1    8    3    0    5     1   \n",
       "\n",
       "   X_11  X_12  X_13  X_14  X_15  MULTIPLE_OFFENSE  \n",
       "0   174   1.0    92    29    36                 0  \n",
       "1   236   1.0   103   142    34                 1  \n",
       "2   174   1.0   110    93    34                 1  \n",
       "3   249   1.0    72    29    34                 1  \n",
       "4   174   0.0   112    29    43                 1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23856, 18)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =x.iloc[:, :-1]\n",
    "y = x.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =x.iloc[:, 2:-1]\n",
    "y = x.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23856, 17)\n",
      "(23856,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are 1 columns with missing values : \n",
      "[('X_12', 182)] \n"
     ]
    }
   ],
   "source": [
    "missing =X.isna().sum(axis=0).sort_values(ascending=False)\n",
    "missing_value_columns = missing[missing>0]\n",
    "print('They are %s columns with missing values : \\n%s ' %(missing_value_columns.count() , [(index , value) for (index , value) in missing_value_columns.iteritems()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_value(X):\n",
    "    dataset =X\n",
    "    dataset['X_12'].fillna(dataset['X_12'].median() , inplace = True)\n",
    "    return dataset\n",
    "\n",
    "X = impute_value(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are 0 columns with missing values : \n",
      "[] \n"
     ]
    }
   ],
   "source": [
    "missing =X.isna().sum(axis=0).sort_values(ascending=False)\n",
    "missing_value_columns = missing[missing>0]\n",
    "print('They are %s columns with missing values : \\n%s ' %(missing_value_columns.count() , [(index , value) for (index , value) in missing_value_columns.iteritems()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 2 object variables : \n",
      " ['INCIDENT_ID', 'DATE']\n"
     ]
    }
   ],
   "source": [
    "object = list(X.select_dtypes(include=[np.object]))\n",
    "print('Here are the %s object variables : \\n %s' %(len(object) , object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train ,y_test = train_test_split(X,y , test_size =0.2 , random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19084, 15)\n",
      "(4772, 15)\n",
      "(19084,)\n",
      "(4772,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19084, 15)\n",
      "(4772, 15)\n",
      "(19084,)\n",
      "(4772,)\n"
     ]
    }
   ],
   "source": [
    "X_train =X_train.values\n",
    "# print(X_train.dtypes) :: to checkkk if the X_train is converted into numpy array or not [if error occur it is , if not it's not]\n",
    "X_test =X_test.values\n",
    "y_train=y_train.values\n",
    "y_test =y_test.values\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6 ,activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6 ,activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1 ,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0497 - acc: 0.9816\n",
      "Epoch 2/100\n",
      "19084/19084 [==============================] - 1s 47us/sample - loss: 0.0496 - acc: 0.9818\n",
      "Epoch 3/100\n",
      "19084/19084 [==============================] - 1s 48us/sample - loss: 0.0495 - acc: 0.9818\n",
      "Epoch 4/100\n",
      "19084/19084 [==============================] - 1s 47us/sample - loss: 0.0495 - acc: 0.9818\n",
      "Epoch 5/100\n",
      "19084/19084 [==============================] - 1s 50us/sample - loss: 0.0492 - acc: 0.9819\n",
      "Epoch 6/100\n",
      "19084/19084 [==============================] - 1s 45us/sample - loss: 0.0492 - acc: 0.9822\n",
      "Epoch 7/100\n",
      "19084/19084 [==============================] - 1s 48us/sample - loss: 0.0490 - acc: 0.9817\n",
      "Epoch 8/100\n",
      "19084/19084 [==============================] - 1s 45us/sample - loss: 0.0491 - acc: 0.9815\n",
      "Epoch 9/100\n",
      "19084/19084 [==============================] - 1s 48us/sample - loss: 0.0488 - acc: 0.9819\n",
      "Epoch 10/100\n",
      "19084/19084 [==============================] - 1s 47us/sample - loss: 0.0488 - acc: 0.9818\n",
      "Epoch 11/100\n",
      "19084/19084 [==============================] - 1s 58us/sample - loss: 0.0485 - acc: 0.9819\n",
      "Epoch 12/100\n",
      "19084/19084 [==============================] - 1s 44us/sample - loss: 0.0485 - acc: 0.9819\n",
      "Epoch 13/100\n",
      "19084/19084 [==============================] - 1s 42us/sample - loss: 0.0483 - acc: 0.9814\n",
      "Epoch 14/100\n",
      "19084/19084 [==============================] - 1s 45us/sample - loss: 0.0484 - acc: 0.9816\n",
      "Epoch 15/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0485 - acc: 0.9819\n",
      "Epoch 16/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0486 - acc: 0.9816\n",
      "Epoch 17/100\n",
      "19084/19084 [==============================] - 1s 60us/sample - loss: 0.0480 - acc: 0.9821\n",
      "Epoch 18/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0481 - acc: 0.9812\n",
      "Epoch 19/100\n",
      "19084/19084 [==============================] - 1s 44us/sample - loss: 0.0481 - acc: 0.9824\n",
      "Epoch 20/100\n",
      "19084/19084 [==============================] - 1s 42us/sample - loss: 0.0482 - acc: 0.9819\n",
      "Epoch 21/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0480 - acc: 0.9820\n",
      "Epoch 22/100\n",
      "19084/19084 [==============================] - 1s 51us/sample - loss: 0.0480 - acc: 0.9824\n",
      "Epoch 23/100\n",
      "19084/19084 [==============================] - 1s 47us/sample - loss: 0.0481 - acc: 0.9823\n",
      "Epoch 24/100\n",
      "19084/19084 [==============================] - 1s 42us/sample - loss: 0.0480 - acc: 0.9828\n",
      "Epoch 25/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0478 - acc: 0.9822\n",
      "Epoch 26/100\n",
      "19084/19084 [==============================] - 1s 45us/sample - loss: 0.0477 - acc: 0.9826\n",
      "Epoch 27/100\n",
      "19084/19084 [==============================] - 1s 48us/sample - loss: 0.0479 - acc: 0.9822\n",
      "Epoch 28/100\n",
      "19084/19084 [==============================] - 1s 49us/sample - loss: 0.0480 - acc: 0.9822\n",
      "Epoch 29/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0475 - acc: 0.9821\n",
      "Epoch 30/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0476 - acc: 0.9819\n",
      "Epoch 31/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0475 - acc: 0.9822\n",
      "Epoch 32/100\n",
      "19084/19084 [==============================] - 1s 42us/sample - loss: 0.0476 - acc: 0.9823\n",
      "Epoch 33/100\n",
      "19084/19084 [==============================] - 1s 44us/sample - loss: 0.0475 - acc: 0.9822\n",
      "Epoch 34/100\n",
      "19084/19084 [==============================] - 1s 49us/sample - loss: 0.0474 - acc: 0.9825\n",
      "Epoch 35/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0476 - acc: 0.9824\n",
      "Epoch 36/100\n",
      "19084/19084 [==============================] - 1s 54us/sample - loss: 0.0473 - acc: 0.9824\n",
      "Epoch 37/100\n",
      "19084/19084 [==============================] - 1s 43us/sample - loss: 0.0475 - acc: 0.9826\n",
      "Epoch 38/100\n",
      "19084/19084 [==============================] - 1s 56us/sample - loss: 0.0476 - acc: 0.9822\n",
      "Epoch 39/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0471 - acc: 0.9825\n",
      "Epoch 40/100\n",
      "19084/19084 [==============================] - 1s 66us/sample - loss: 0.0472 - acc: 0.9824\n",
      "Epoch 41/100\n",
      "19084/19084 [==============================] - 1s 61us/sample - loss: 0.0472 - acc: 0.9824\n",
      "Epoch 42/100\n",
      "19084/19084 [==============================] - 2s 87us/sample - loss: 0.0471 - acc: 0.9823\n",
      "Epoch 43/100\n",
      "19084/19084 [==============================] - 1s 64us/sample - loss: 0.0471 - acc: 0.9822\n",
      "Epoch 44/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0471 - acc: 0.9823\n",
      "Epoch 45/100\n",
      "19084/19084 [==============================] - 1s 64us/sample - loss: 0.0472 - acc: 0.9823\n",
      "Epoch 46/100\n",
      "19084/19084 [==============================] - 1s 66us/sample - loss: 0.0469 - acc: 0.9824\n",
      "Epoch 47/100\n",
      "19084/19084 [==============================] - 1s 58us/sample - loss: 0.0469 - acc: 0.9822\n",
      "Epoch 48/100\n",
      "19084/19084 [==============================] - 1s 62us/sample - loss: 0.0468 - acc: 0.9823\n",
      "Epoch 49/100\n",
      "19084/19084 [==============================] - 1s 61us/sample - loss: 0.0469 - acc: 0.9824\n",
      "Epoch 50/100\n",
      "19084/19084 [==============================] - 1s 69us/sample - loss: 0.0476 - acc: 0.9825\n",
      "Epoch 51/100\n",
      "19084/19084 [==============================] - 1s 62us/sample - loss: 0.0468 - acc: 0.9826\n",
      "Epoch 52/100\n",
      "19084/19084 [==============================] - 2s 94us/sample - loss: 0.0467 - acc: 0.9823\n",
      "Epoch 53/100\n",
      "19084/19084 [==============================] - 2s 110us/sample - loss: 0.0469 - acc: 0.9827s - loss: 0.0488 - acc: 0 - ETA: 1s - loss: 0.0\n",
      "Epoch 54/100\n",
      "19084/19084 [==============================] - 2s 82us/sample - loss: 0.0467 - acc: 0.9824\n",
      "Epoch 55/100\n",
      "19084/19084 [==============================] - 2s 92us/sample - loss: 0.0467 - acc: 0.9823\n",
      "Epoch 56/100\n",
      "19084/19084 [==============================] - 1s 78us/sample - loss: 0.0466 - acc: 0.9828\n",
      "Epoch 57/100\n",
      "19084/19084 [==============================] - 1s 71us/sample - loss: 0.0467 - acc: 0.9825\n",
      "Epoch 58/100\n",
      "19084/19084 [==============================] - 1s 60us/sample - loss: 0.0466 - acc: 0.9827\n",
      "Epoch 59/100\n",
      "19084/19084 [==============================] - 1s 45us/sample - loss: 0.0466 - acc: 0.9824\n",
      "Epoch 60/100\n",
      "19084/19084 [==============================] - 1s 55us/sample - loss: 0.0466 - acc: 0.9822\n",
      "Epoch 61/100\n",
      "19084/19084 [==============================] - 2s 94us/sample - loss: 0.0463 - acc: 0.98310s - loss: 0.0471 - acc: 0.\n",
      "Epoch 62/100\n",
      "19084/19084 [==============================] - 2s 83us/sample - loss: 0.0464 - acc: 0.9823\n",
      "Epoch 63/100\n",
      "19084/19084 [==============================] - 1s 77us/sample - loss: 0.0463 - acc: 0.98201s - lo\n",
      "Epoch 64/100\n",
      "19084/19084 [==============================] - 1s 65us/sample - loss: 0.0464 - acc: 0.9829\n",
      "Epoch 65/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0463 - acc: 0.9830\n",
      "Epoch 66/100\n",
      "19084/19084 [==============================] - 1s 67us/sample - loss: 0.0464 - acc: 0.9825\n",
      "Epoch 67/100\n",
      "19084/19084 [==============================] - 1s 69us/sample - loss: 0.0463 - acc: 0.9830\n",
      "Epoch 68/100\n",
      "19084/19084 [==============================] - 1s 58us/sample - loss: 0.0462 - acc: 0.9828\n",
      "Epoch 69/100\n",
      "19084/19084 [==============================] - 1s 65us/sample - loss: 0.0464 - acc: 0.9826\n",
      "Epoch 70/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0465 - acc: 0.9824\n",
      "Epoch 71/100\n",
      "19084/19084 [==============================] - 1s 57us/sample - loss: 0.0461 - acc: 0.9827\n",
      "Epoch 72/100\n",
      "19084/19084 [==============================] - 1s 60us/sample - loss: 0.0459 - acc: 0.9828\n",
      "Epoch 73/100\n",
      "19084/19084 [==============================] - 1s 56us/sample - loss: 0.0468 - acc: 0.9828\n",
      "Epoch 74/100\n",
      "19084/19084 [==============================] - 1s 45us/sample - loss: 0.0463 - acc: 0.9827\n",
      "Epoch 75/100\n",
      "19084/19084 [==============================] - 1s 44us/sample - loss: 0.0461 - acc: 0.9823\n",
      "Epoch 76/100\n",
      "19084/19084 [==============================] - 1s 40us/sample - loss: 0.0458 - acc: 0.9829\n",
      "Epoch 77/100\n",
      "19084/19084 [==============================] - 1s 44us/sample - loss: 0.0460 - acc: 0.9826\n",
      "Epoch 78/100\n",
      "19084/19084 [==============================] - 1s 46us/sample - loss: 0.0462 - acc: 0.9829\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19084/19084 [==============================] - 1s 50us/sample - loss: 0.0457 - acc: 0.9828\n",
      "Epoch 80/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0459 - acc: 0.9830\n",
      "Epoch 81/100\n",
      "19084/19084 [==============================] - 1s 60us/sample - loss: 0.0459 - acc: 0.9828\n",
      "Epoch 82/100\n",
      "19084/19084 [==============================] - 1s 57us/sample - loss: 0.0459 - acc: 0.9828\n",
      "Epoch 83/100\n",
      "19084/19084 [==============================] - 1s 55us/sample - loss: 0.0455 - acc: 0.9827\n",
      "Epoch 84/100\n",
      "19084/19084 [==============================] - 1s 57us/sample - loss: 0.0459 - acc: 0.9828\n",
      "Epoch 85/100\n",
      "19084/19084 [==============================] - 1s 57us/sample - loss: 0.0456 - acc: 0.9836\n",
      "Epoch 86/100\n",
      "19084/19084 [==============================] - 1s 56us/sample - loss: 0.0455 - acc: 0.9830\n",
      "Epoch 87/100\n",
      "19084/19084 [==============================] - 1s 50us/sample - loss: 0.0458 - acc: 0.9828\n",
      "Epoch 88/100\n",
      "19084/19084 [==============================] - 1s 47us/sample - loss: 0.0453 - acc: 0.9829\n",
      "Epoch 89/100\n",
      "19084/19084 [==============================] - 1s 67us/sample - loss: 0.0455 - acc: 0.9828\n",
      "Epoch 90/100\n",
      "19084/19084 [==============================] - 1s 63us/sample - loss: 0.0454 - acc: 0.9826\n",
      "Epoch 91/100\n",
      "19084/19084 [==============================] - ETA: 0s - loss: 0.0449 - acc: 0.983 - 1s 54us/sample - loss: 0.0455 - acc: 0.9832\n",
      "Epoch 92/100\n",
      "19084/19084 [==============================] - 1s 53us/sample - loss: 0.0455 - acc: 0.9829\n",
      "Epoch 93/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0453 - acc: 0.9830\n",
      "Epoch 94/100\n",
      "19084/19084 [==============================] - 1s 50us/sample - loss: 0.0452 - acc: 0.9833\n",
      "Epoch 95/100\n",
      "19084/19084 [==============================] - 1s 52us/sample - loss: 0.0457 - acc: 0.9826\n",
      "Epoch 96/100\n",
      "19084/19084 [==============================] - 1s 47us/sample - loss: 0.0451 - acc: 0.9829\n",
      "Epoch 97/100\n",
      "19084/19084 [==============================] - 1s 59us/sample - loss: 0.0452 - acc: 0.9830\n",
      "Epoch 98/100\n",
      "19084/19084 [==============================] - 1s 68us/sample - loss: 0.0453 - acc: 0.9832\n",
      "Epoch 99/100\n",
      "19084/19084 [==============================] - 1s 44us/sample - loss: 0.0453 - acc: 0.9835\n",
      "Epoch 100/100\n",
      "19084/19084 [==============================] - 1s 57us/sample - loss: 0.0449 - acc: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cdf0dc9e48>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 100, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred) , 1) , y_test.reshape(len(y_test) , 1)) ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 151   82]\n",
      " [  19 4520]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9788348700754401"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score( y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.648068669527897\n"
     ]
    }
   ],
   "source": [
    "print(f\"precision {151/(151+82)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             [[ 151   82]\n",
    "#              [  19 4520]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recall 0.888235294117647\n"
     ]
    }
   ],
   "source": [
    "print(f\" recall {151/(151+19)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f1 square 75.12987012987013\n"
     ]
    }
   ],
   "source": [
    "print(f\" f1 square {2* ((65*89)/(65+89))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy 0.9788348700754401\n"
     ]
    }
   ],
   "source": [
    "print(f\" accuracy {(151+4520)/(151+4520+19+82)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
